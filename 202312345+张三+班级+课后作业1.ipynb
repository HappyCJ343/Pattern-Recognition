{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 模式识别课后作业1\n",
        "\n",
        "- 姓名：张三（示例，请根据实际情况修改）\n",
        "- 学号：202312345（示例，请根据实际情况修改）\n",
        "- 班级：模式识别班级（示例，请根据实际情况修改）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 作业目标\n",
        "\n",
        "1. 下载并探索红酒质量数据集，完成特征工程分析；\n",
        "2. 将质量评分转换为二分类标签，并观察类别分布；\n",
        "3. 实现基于梯度下降的逻辑回归模型并进行交叉验证；\n",
        "4. 调用 scikit-learn 中的逻辑回归模型进行对比实验；\n",
        "5. 对实验过程和结果进行总结归纳。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 环境与数据准备\n",
        "\n",
        "下面的代码单元会自动检查数据集是否存在于 `data/winequality-red.csv`，\n",
        "若不存在则尝试从 UCI 仓库下载。若在本地/教学平台运行时无法联网，\n",
        "请手动将数据集放置于指定路径。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import urllib.request\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (8, 5)\n",
        "sns.set_theme(style='whitegrid', context='notebook')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "DATA_DIR = Path('data')\n",
        "DATA_DIR.mkdir(exist_ok=True)\n",
        "DATA_PATH = DATA_DIR / 'winequality-red.csv'\n",
        "DATA_URL = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
        "\n",
        "if not DATA_PATH.exists():\n",
        "    try:\n",
        "        print('Downloading dataset ...')\n",
        "        urllib.request.urlretrieve(DATA_URL, DATA_PATH)\n",
        "        print('Download completed.')\n",
        "    except Exception as exc:\n",
        "        raise RuntimeError('数据集不存在且下载失败，请手动将 winequality-red.csv 放置于 data 目录下。') from exc\n",
        "\n",
        "df = pd.read_csv(DATA_PATH, sep=';')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 数据理解与初步探索\n",
        "\n",
        "通过基础统计信息与缺失值检测来了解数据的整体情况。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "df.describe().T"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 标签转换与类别分布\n",
        "\n",
        "根据课程要求，将评分大于等于 7 的样本视为高质量（标签 1），\n",
        "其余视为低质量（标签 0），并观察二分类后的类别分布。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "THRESHOLD = 7\n",
        "df['label'] = (df['quality'] >= THRESHOLD).astype(int)\n",
        "class_counts = df['label'].value_counts().rename({0: '低质量 (0)', 1: '高质量 (1)'})\n",
        "class_ratio = class_counts / len(df)\n",
        "display(class_counts.to_frame('数量'))\n",
        "display(class_ratio.to_frame('占比'))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "sns.countplot(x='quality', data=df, ax=axes[0], palette='crest')\n",
        "axes[0].set_title('原始质量评分分布')\n",
        "axes[0].set_xlabel('quality')\n",
        "axes[0].set_ylabel('count')\n",
        "\n",
        "sns.countplot(x='label', data=df, ax=axes[1], palette='flare')\n",
        "axes[1].set_title('二分类标签分布')\n",
        "axes[1].set_xlabel('label (0=低质量, 1=高质量)')\n",
        "axes[1].set_ylabel('count')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 特征工程与可视化分析\n",
        "\n",
        "绘制若干特征随标签变化的分布，以及相关系数热力图，用于辅助理解特征与目标变量的关系。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "feature_cols = [col for col in df.columns if col not in {'quality', 'label'}]\n",
        "melted = df.melt(id_vars='label', value_vars=feature_cols, var_name='feature', value_name='value')\n",
        "plt.figure(figsize=(14, 10))\n",
        "sns.boxplot(data=melted, x='value', y='feature', hue='label', orient='h', palette='Set2')\n",
        "plt.title('不同标签下的特征分布（箱线图）')\n",
        "plt.xlabel('取值范围')\n",
        "plt.ylabel('特征名')\n",
        "plt.legend(title='标签', loc='upper right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "corr = df[feature_cols + ['label']].corr()\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', square=True, cbar_kws={'shrink': 0.8})\n",
        "plt.title('特征与标签的相关系数热力图')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 数据预处理\n",
        "\n",
        "由于各特征的量纲与范围不同，先使用 `StandardScaler` 对特征进行标准化，为梯度下降与逻辑回归训练提供更稳定的数值条件。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "X = df[feature_cols].to_numpy(dtype=float)\n",
        "y = df['label'].to_numpy(dtype=int)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_scaled[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. 手动实现逻辑回归（梯度下降）\n",
        "\n",
        "实现一个支持 L2 正则化的逻辑回归类，使用批量梯度下降更新参数。\n",
        "训练过程中记录损失变化，便于观察收敛情况。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "class LogisticRegressionGD:\n",
        "    def __init__(self, lr=0.1, max_iter=2000, tol=1e-6, l2=0.0, verbose=False):\n",
        "        self.lr = lr\n",
        "        self.max_iter = max_iter\n",
        "        self.tol = tol\n",
        "        self.l2 = l2\n",
        "        self.verbose = verbose\n",
        "        self.theta_ = None\n",
        "        self.loss_history_ = []\n",
        "\n",
        "    @staticmethod\n",
        "    def _sigmoid(z):\n",
        "        return 1.0 / (1.0 + np.exp(-z))\n",
        "\n",
        "    def _loss(self, X, y):\n",
        "        logits = X @ self.theta_\n",
        "        probs = self._sigmoid(logits)\n",
        "        eps = 1e-12\n",
        "        ce = -np.mean(y * np.log(probs + eps) + (1 - y) * np.log(1 - probs + eps))\n",
        "        reg = 0.5 * self.l2 * np.sum(self.theta_[1:] ** 2)\n",
        "        return ce + reg\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        X_bias = np.hstack([np.ones((n_samples, 1)), X])\n",
        "        self.theta_ = np.zeros(n_features + 1)\n",
        "        self.loss_history_.clear()\n",
        "\n",
        "        for i in range(self.max_iter):\n",
        "            logits = X_bias @ self.theta_\n",
        "            probs = self._sigmoid(logits)\n",
        "            errors = probs - y\n",
        "\n",
        "            grad = X_bias.T @ errors / n_samples\n",
        "            grad[1:] += self.l2 * self.theta_[1:]\n",
        "\n",
        "            self.theta_ -= self.lr * grad\n",
        "            loss = self._loss(X_bias, y)\n",
        "            self.loss_history_.append(loss)\n",
        "\n",
        "            if self.verbose and (i % 100 == 0 or i == self.max_iter - 1):\n",
        "                print(f'Iter {i:4d}, loss={loss:.6f}')\n",
        "\n",
        "            if i > 0 and abs(self.loss_history_[-2] - loss) < self.tol:\n",
        "                if self.verbose:\n",
        "                    print(f'Converged at iteration {i}.')\n",
        "                break\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        if self.theta_ is None:\n",
        "            raise ValueError('Model has not been fitted yet.')\n",
        "        X_bias = np.hstack([np.ones((X.shape[0], 1)), X])\n",
        "        return self._sigmoid(X_bias @ self.theta_)\n",
        "\n",
        "    def predict(self, X, threshold=0.5):\n",
        "        proba = self.predict_proba(X)\n",
        "        return (proba >= threshold).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def evaluate_model(model, X_train, y_train, X_valid, y_valid):\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_valid)\n",
        "    return {\n",
        "        'accuracy': accuracy_score(y_valid, preds),\n",
        "        'precision': precision_score(y_valid, preds, zero_division=0),\n",
        "        'recall': recall_score(y_valid, preds, zero_division=0),\n",
        "        'f1': f1_score(y_valid, preds, zero_division=0)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "manual_scores = []\n",
        "\n",
        "for fold, (train_idx, valid_idx) in enumerate(kf.split(X_scaled), start=1):\n",
        "    X_train, X_valid = X_scaled[train_idx], X_scaled[valid_idx]\n",
        "    y_train, y_valid = y[train_idx], y[valid_idx]\n",
        "\n",
        "    model = LogisticRegressionGD(lr=0.1, max_iter=5000, tol=1e-6, l2=0.01)\n",
        "    fold_scores = evaluate_model(model, X_train, y_train, X_valid, y_valid)\n",
        "    fold_scores['fold'] = fold\n",
        "    manual_scores.append(fold_scores)\n",
        "\n",
        "manual_df = pd.DataFrame(manual_scores).set_index('fold')\n",
        "manual_df.assign(mean=manual_df.mean(axis=1))\n",
        "manual_df\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "manual_summary = manual_df.mean().to_frame(name='手写逻辑回归 (5-fold mean)')\n",
        "manual_summary.T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. scikit-learn 逻辑回归基准\n",
        "\n",
        "使用 scikit-learn 中的 `LogisticRegression` 进行 5 折交叉验证，并与手动实现的结果进行对比。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "sklearn_scores = []\n",
        "for fold, (train_idx, valid_idx) in enumerate(kf.split(X_scaled), start=1):\n",
        "    X_train, X_valid = X_scaled[train_idx], X_scaled[valid_idx]\n",
        "    y_train, y_valid = y[train_idx], y[valid_idx]\n",
        "\n",
        "    clf = LogisticRegression(max_iter=5000, C=1.0, solver='lbfgs')\n",
        "    clf.fit(X_train, y_train)\n",
        "    preds = clf.predict(X_valid)\n",
        "\n",
        "    sklearn_scores.append({\n",
        "        'fold': fold,\n",
        "        'accuracy': accuracy_score(y_valid, preds),\n",
        "        'precision': precision_score(y_valid, preds, zero_division=0),\n",
        "        'recall': recall_score(y_valid, preds, zero_division=0),\n",
        "        'f1': f1_score(y_valid, preds, zero_division=0)\n",
        "    })\n",
        "\n",
        "sklearn_df = pd.DataFrame(sklearn_scores).set_index('fold')\n",
        "sklearn_df\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "comparison = pd.concat({\n",
        "    '手写逻辑回归': manual_df.mean(),\n",
        "    'sklearn 逻辑回归': sklearn_df.mean()\n",
        "}, axis=1).T\n",
        "comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. 小结与思考\n",
        "\n",
        "- 通过特征探索可以发现酸度、硫含量等特征对酒的质量存在一定影响，\n",
        "  但不同指标之间存在较强相关性，需注意多重共线性对模型的影响；\n",
        "- 手写的逻辑回归在标准化和适当的学习率、正则化配置下能够收敛到与库函数相近的性能；\n",
        "- scikit-learn 的实现对超参数更不敏感，且训练速度较快，适用于快速实验；\n",
        "- 实验中可以继续尝试调节阈值、采用分层交叉验证、引入特征选择等方式进一步优化模型表现。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}